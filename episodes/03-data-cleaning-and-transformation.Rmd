---
title: "Data cleaning & transformation with dplyr"
keypoints:
- "Use the `dplyr` package to manipulate dataframes."
- "Use `select()` to choose variables from a dataframe."
- "Use `filter()` to choose data based on values."
- 'Use `group_by()` and `summarize()` to work with subsets of data.'
- "Use `mutate()` to create new variables."
objectives:
- "Describe the purpose of an R package and the **`dplyr`** and **`tidyr`** packages."
- "Select certain columns in a data frame with the **`dplyr`** function `select`."
- "Select certain rows in a data frame according to filtering conditions with the **`dplyr`**  function `filter`."
- "Link the output of one **`dplyr`** function to the input of another function with the 'pipe' operator `%>%`."
- "Add new columns to a data frame that are functions of existing columns with `mutate`."
- "Use the split-apply-combine concept for data analysis."
- "Use `summarize`, `group_by`, and `count` to split a data frame into groups of observations, apply a summary statistics for each group, and then combine the results."
- "Describe the concept of a wide and a long table format and for which purpose those formats are useful."
- "Describe what key-value pairs are."
- "Reshape a data frame from long to wide format and back with the `spread` and `gather` commands from the **`tidyr`** package."
- "Export a data frame to a csv file."
questions:
- "How can I select specific rows and/or columns from a data frame?"
- "How can I combine multiple commands into a single command?"
- "How can create new columns or remove existing columns from a data frame?"
- "How can I reformat a dataframe to meet my needs?"
teaching: 50
exercises: 30
source: Rmd
---
  
```{r, include=FALSE}
source("../bin/download_data.R")
source("../bin/chunk-options.R")
knitr_fig_path("03-")
library(readr)
books <- read_csv("./data/books.csv")
```


## Getting set up

### Open your R Project file

If you have not already done so, open your R Project file (`library_carpentry.Rproj`) created in the `Before We Start` lesson.

**If you did not complete that step** then do the following:

* Under the `File` menu, click on `New project`, choose `New directory`, then
`New project`
* Enter the name `library_carpentry` for this new folder (or "directory"). This
will be your **working directory** for the rest of the day.
* Click on `Create project`
* Create a new file where we will type our scripts. Go to File > New File > R
script. Click the save icon on your toolbar and save your script as
"`script.R`".
* Copy and paste the below lines of code to create three new subdirectories and download the data:

```{r create-dirs, eval=FALSE}
library(fs)   # https://fs.r-lib.org/.  fs is a cross-platform, uniform interface to file system operations via R. 
dir_create("data")
dir_create("data_output")
dir_create("fig_output")
download.file("https://ndownloader.figshare.com/files/22031487",
              "data/books.csv", mode = "wb")
```

### Load the `tidyverse` and data frame into your R session

Load the `tidyverse` 

```{r load-data, purl=FALSE}
library(tidyverse)
```

And the `books` data we saved in the previous lesson. 

```{r, eval=FALSE, purl=FALSE}
books <- read_csv("data/books.csv")  # load the data and assign it to books
```

## Transforming data with `dplyr`

We are now entering the data cleaning and transforming phase. While it is
possible to do much of the following using Base R functions (in other words,
without loading an external package) `dplyr` makes it much easier. Like many of
the most useful R packages, `dplyr` was developed by data scientist
[http://hadley.nz/](Hadley Wickham).

`dplyr` is a package for making tabular data manipulation easier by using a
limited set of functions that can be combined to extract and summarize insights
from your data. It pairs nicely with **`tidyr`** which enables you to swiftly
convert between different data formats (long vs. wide) for plotting and
analysis.

`dplyr` is also part of the `tidyverse.` Let's make sure we are all on the same
page by loading the `tidyverse` and the `books` dataset we downloaded earlier.


We're going to learn some of the most common **`dplyr`** functions:

- `rename()`: rename columns
- `recode()`: recode values in a column
- `select()`: subset columns
- `filter()`: subset rows on conditions
- `mutate()`: create new columns by using information from other columns
- `group_by()` and `summarize()`: create summary statistics on grouped data
- `arrange()`: sort results
- `count()`: count discrete values

## Renaming variables

It is often necessary to rename variables to make them more meaningful. If you
print the names of the sample `books` dataset you can see that some of the
vector names are not particularly helpful:

```{r renaming1, purl=FALSE}
glimpse(books)  # print names of the books data frame to the console
```

There are many ways to rename variables in R, but the `rename()` function
in the `dplyr` package is the easiest and most straightforward. The new
variable name comes first. See `help(rename)`.

Here we rename the X245.ab variable. Make sure you assign the output to your
`books` value, otherwise it will just print it to the console. In other words,
we are overwriting the previous `books` value with the new one, with `X245.ab`
renamed to `title`.

```{r renaming2, comment=NA}
# rename the . Make sure you return (<-) the output to your 
# variable, otherwise it will just print it to the console
books <- rename(books,
                title = X245.ab)
```

> ## Side note:
>
> Where does `X245.ab` come from? That is the MARC field 245|ab. However,
because R variables cannot start with a number, R automatically inserted and X,
and because pipes | are not allowed in variable names, R replaced it with a
period. {: .callout}


```{r, purl=FALSE}
# rename multiple variables at once
books <- rename(books,
                author = X245.c,
                callnumber = CALL...BIBLIO.,
                isbn = ISN,
                pubyear = X008.Date.One,
                subCollection = BCODE1,
                format = BCODE2,
                location = LOCATION,
                tot_chkout = TOT.CHKOUT,
                loutdate = LOUTDATE,
                subject = SUBJECT)
books
```


> ## Rename `CALL...ITEM.`
>
> 1. Use `rename()` to rename the `CALL...ITEM.` column to `callnumber2`. Remember to add the period to the end of the `CALL...ITEM.` value
>
> > ## Solution
> > ```{r, answer=TRUE}
> > books <- rename(books,
> >                 callnumber2 = CALL...ITEM.)
> > ```
> {: .solution}
{: .challenge}

## Recoding values
It is often necessary to recode or reclassify values in your data. For example,
in the sample dataset provided to you, the `sub_collection` (formerly `BCODE1`)
and `format` (formerly `BCODE2`) variables contain single characters.

<figure>
```{r, echo=FALSE, fig.cap="Sub-Collection (formerly BCODE1) export from Sierra"}	
knitr::include_graphics("../fig/BCODE1.PNG")
```
<figcaption>
Sub-Collection (formerly BCODE1) export from Sierra
</figcaption>
</figure>

<figure>
```{r, echo=FALSE, fig.cap="Format (formerly BCODE2) export from Sierra"}	
knitr::include_graphics("../fig/BCODE2.PNG")
```
<figcaption>
Format (formerly BCODE2) export from Sierra
</figcaption>
</figure>

You can do this easily using the `recode()` function, also in the `dplyr`
package. Unlike `rename()`, the old value comes first here. Also notice that we
are overwriting the `books$subCollection` variable.


```{r, comment=FALSE}
# first print to the console all of the unique values you will need to recode
distinct(books, subCollection)

books$subCollection <- recode(books$subCollection,
                                      "-" = "general collection",
                                      u = "government documents",
                                      r = "reference",
                                      b = "k-12 materials",
                                      j = "juvenile",
                                      s = "special collections",
                                      c = "computer files",
                                      t = "theses",
                                      a = "archives",
                                      z = "reserves")
books 
```

Do the same for the `format` column. Note that you must put `"5"` and `"4"` into
quotation marks for the function to operate correctly.

```{r, comment=FALSE, purl=FALSE}
books$format <- recode(books$format,
                              a = "book",
                              e = "serial",
                              w = "microform",
                              s = "e-gov doc",
                              o = "map",
                              n = "database",
                              k = "cd-rom",
                              m = "image",
                              "5" = "kit/object",
                              "4" = "online video")
```

## Subsetting dataframes

### Subsetting using `filter()` in the `dplyr` package

In the last lesson we learned how to subset a data frame using brackets. As with
other R functions, the `dplyr` package makes it much more straightforward, using
the `filter()` function.

Here we will create a subset of `books` called `booksOnly`, which includes only
those items where the format is books. Notice that we use two equal signs `==`
as the logical operator:

```{r, comment=FALSE, purl=FALSE}
booksOnly <- filter(books, format == "book") # filter books to return only those items where the format is books
```

You can also use multiple filter conditions. Here, the order matters: first we
filter to include only books, then of the results, we include only items that
have more than zero checkouts.

```{r, comment=FALSE, purl=FALSE}
bookCheckouts <- filter(books,
                        format == "book",
                        tot_chkout > 0)
```

How many items were removed? You can find out functionally with:

```{r, comment=FALSE, purl=FALSE}
nrow(books) - nrow(bookCheckouts)
```

You can then check the summary statistics of checkouts for books with more than zero checkouts. Notice how different these numbers are from the previous lesson, when we kept zero in. The median is now 3 and the mean is 5.

```{r, comment=FALSE, purl=FALSE}
summary(bookCheckouts$tot_chkout)
```

If you want to filter on multiple conditions within the same variable, use the `%in%` operator combined with a vector of all the values you wish to include within `c()`. For example, you may want to include only items in the format `serial` and `microform`:

```{r, comment=FALSE, purl=FALSE}
serial_microform <- filter(books, format %in% c("serial", "microform"))
```

> ## Filtering with `filter()`
>
> 1. Use `filter()` to create a data frame called `booksJuv` consisting of `format` books and `subCollection` juvenile materials. 
>
> 2. Use `mean()` to check the average number of checkouts for the `booksJuv` data frame.
>
> > ## Solution
> > ```{r, answer=TRUE}
> > booksJuv <- filter(books,
                   format == "book",
                   subCollection ==  "juvenile")
    mean(booksJuv$tot_chkout)
> > ```
> {: .solution}
{: .challenge}

  
## Selecting variables

The `select()` function allows you to keep or remove specific columns It also
provides a convenient way to reorder variables.

```{r select, comment=NA}
# specify the variables you want to keep by name
booksTitleCheckouts <- select(books, title, tot_chkout)
booksTitleCheckouts

# specify the variables you want to remove with a -
books <- select(books, -location)

# reorder columns, combined with everything()
booksReordered <- select(books, title, tot_chkout, loutdate, everything())
```


## Ordering data
The `arrange()` function in the `dplyr` package allows you to sort your data by alphabetical or numerical order. 

```{r arrange, comment=NA}
booksTitleArrange <- arrange(books, title)

# use desc() to sort a variable in descending order
booksHighestChkout <- arrange(books, desc(tot_chkout))
booksHighestChkout

# order data based on multiple variables (e.g. sort first by checkout, then by publication year)
booksChkoutYear <- arrange(books, desc(tot_chkout), desc(pubyear))
```


## Creating new variables
The `mutate()` function allows you to create new variables. Here, we use the
`str_sub()` function from the `stringr` package to extract the first character
of the `callnumber` variable (the call number class) and put it into a new column called
`call_class`. 

```{r mutate, comment=NA}
booksLC <- mutate(books,
                  call_class = str_sub(callnumber, 1, 1))
```

There are two numbers because you must specify a start and an end value--here,
we start with the first character, and end with the first character.

`mutate()` is also helpful to coerce a column from one data type to another. For example, we can see there are some errors in the `pubyear` variable--some dates are `19zz` or `uuuu`. As a result, this variable was read in as a `character` rather than an `integer`. 

```{r, comment=NA}
books <- mutate(books, pubyear = as.integer(pubyear))
```

We see the error message `NAs introduced by coercion`. This is because non-numerical variables become `NA` and the remainder become integers.

## Pattern matching

Cleaning text with the `stringr` package is easier when you have a basic understanding of 'regex', or regular expression pattern matching. Regex is especially useful for manipulating strings (alphanumeric data), and is the backbone of search-and-replace operations in most applications.  Pattern matching is common to all programming languages but regex syntax is often code-language specific.  Below, find an example of using pattern matching to find and replace data in R:  

1. Remove the trailing slash in the title column
2. Modify the punctuation separating the title from a subtitle

Note:  If the final product of this data will be imported into an ILS, you may not want to alter the MARC specific punctuation.  All other audiences will appreciate the text normalizing steps.

Read more about [matching patterns with regular expressions](https://r4ds.had.co.nz/strings.html#matching-patterns-with-regular-expressions).

```{r}
books %>% 
  mutate(title_modified = str_remove(title, "/$")) %>%     # remove the trailing slash
  mutate(title_modified = str_replace(title_modified, "\\s:\\|", ": ")) %>%   # replace ' :|' with ': '
  select(title_modified, title)
```


## Putting it all together with %>%

The [Pipe
Operator](https://www.datacamp.com/community/tutorials/pipe-r-tutorial) `%>%` is
loaded with the `tidyverse`. It takes the output of one statement and makes it
the input of the next statement. You can think of it as "then" in natural
language. So instead of making a bunch of intermediate data frames and
cluttering up your workspace, you can run multiple functions at once. You can
type the pipe with <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you have
a PC or <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you have a Mac.

So in the following example, the `books` tibble is first called, then
the `format` is filtered to include only `book`, then only the `title` and `tot_chkout`
columns are selected, and finally the data is rearranged from most to least
checkouts.

```{r pipe, comment=NA}
myBooks <- books %>%
  filter(format == "book") %>%
  select(title, tot_chkout) %>%
  arrange(desc(tot_chkout))
myBooks
```


> ## Playing with pipes `%>%`
>
> 1. Create a new data frame `booksKids` with these conditions:
> * `filter()` to include `subCollection` juvenile & k-12 materials and `format` books. 
  * `select()` only title, call number, total checkouts, and publication year
  * `arrange()` by total checkouts in descending order
>
> 2. Use `mean()` to check the average number of checkouts for the `booksKids` data frame.
>
> > ## Solution
> > ```{r, answer=TRUE}
> > booksKids <- books %>%
      filter(subCollection %in% c("juvenile", "k-12 materials"),
      format == "book") %>%
    select(title, callnumber, tot_chkout, pubyear) %>%
    arrange(desc(tot_chkout))
    mean(booksKids$tot_chkout)
> > ```
> {: .solution}
{: .challenge}


## Split-apply-combine data analysis and the `summarize()` function

Many data analysis tasks can be approached using the *split-apply-combine*
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. **`dplyr`** makes this very easy through the use of
the `group_by()` function.

#### The `summarize()` function

`group_by()` is often used together with `summarize()`, which collapses each
group into a single-row summary of that group.  `group_by()` takes as arguments
the column names that contain the **categorical** variables for which you want
to calculate the summary statistics. 

So to compute the average checkouts by format:

```{r, comment=NA}
books %>%
  group_by(format) %>%
  summarize(mean_checkouts = mean(tot_chkout))
```

Books and maps have the highest, and as we would expect, databases, online videos, and serials have zero checkouts.

Here is a more complex example:
```{r, comment=NA}
books %>% 
  filter(format == "book") %>%
  mutate(call_class = str_sub(callnumber, 1, 1)) %>%
  group_by(call_class) %>%
  summarize(count = n(),
            sum_tot_chkout = sum(tot_chkout)) %>%
  arrange(desc(sum_tot_chkout))
```

Let's break this down step by step:
* First we call the `books` data frame
* We then pipe through `filter()` to include only books
* We then create a new column with `mutate()` called `call_class` by using the
`str_sub()` function to keep the first character of the `call_number` variable
* We then `group_by()` our newly created `call_class` variable
* We then create two summary columns by using `summarize()` 
  - take the number `n()` of items per `call_class` and assign it to a column called `count`
  - take the the `sum()` of `tot_chkout` per `call_class` and assign the result to a column called `sum_tot_chkout`
* Finally, we arrange `sum_tot_chkout` in descending order, so we can see the
class with the most total checkouts. We can see it is the `E` class (History of America), followed by `NA` (items with no call number data), followed by `H` (Social Sciences) and `P` (Language and Literature).

## Exporting data

Now that you have learned how to use **`dplyr`** to extract information from
or summarize your raw data, you may want to export these new data sets to share
them with your collaborators or for archival.

Similar to the `read_csv()` function used for reading CSV files into R, there is
a `write_csv()` function that generates CSV files from data frames.

Before using `write_csv()`, we are going to create a new folder, `data_output`,
in our working directory that will store this generated dataset. We don't want
to write generated datasets in the same directory as our raw data. It's good
practice to keep them separate. The `data` folder should only contain the raw,
unaltered data, and should be left alone to make sure we don't delete or modify
it. In contrast, our script will generate the contents of the `data_output`
directory, so even if the files it contains are deleted, we can always
re-generate them.

In preparation for our next lesson on plotting, we are going to create a
version of the dataset with most of the changes we made above. We will first read in the original, then make all the changes with pipes.



```{r, comment=NA, eval=FALSE}
books_reformatted <- read_csv("./data/books.csv") %>%
  rename(title = X245.ab,
         author = X245.c,
         callnumber = CALL...BIBLIO.,
         isbn = ISN,
         pubyear = X008.Date.One,
         subCollection = BCODE1,
         format = BCODE2,
         location = LOCATION,
         tot_chkout = TOT.CHKOUT,
         loutdate = LOUTDATE,
         subject = SUBJECT,
         callnumber2 = CALL...ITEM.) %>%
  mutate(pubyear = as.integer(pubyear),
         call_class = str_sub(callnumber, 1, 1),
         subCollection = recode(subCollection,
                                "-" = "general collection",
                                u = "government documents",
                                r = "reference",
                                b = "k-12 materials",
                                j = "juvenile",
                                s = "special collections",
                                c = "computer files",
                                t = "theses",
                                a = "archives",
                                z = "reserves"),
         format = recode(format,
                         a = "book",
                         e = "serial",
                         w = "microform",
                         s = "e-gov doc",
                         o = "map",
                         n = "database",
                         k = "cd-rom",
                         m = "image",
                         "5" = "kit/object",
                         "4" = "online video"))
```

This chunk of code read the CSV, renamed the variables, used `mutate()` in
combination with `recode()` to recode the `format` and `subCollection` values,
used `mutate()` in combination with `as.integer()` to coerce `pubyear` to
integer, and used `mutate()` in combination with `str_sub` to create the new
varable `call_class`.

We now write it to a CSV and put it in the `data/output` sub-directory:

```{r, comment=NA, eval=FALSE}
write_csv(books_reformatted, "./data_output/books_reformatted.csv")
```

# Help with dplyr
  
* Read more about `dplyr` at <https://dplyr.tidyverse.org/>. 
* In your console, after loading `library(dplyr)`, run `vignette("dplyr")` to read an extremely helpful explanation of how to use it. 
* See the [http://r4ds.had.co.nz/transform.html]("Data Transformation" chapter) in Garrett Grolemund and Hadley Wickham's book *R for Data Science.*
* Watch this Data School video: [https://www.youtube.com/watch?v=jWjqLW-u3hc](Hands-on dplyr tutorial for faster data manipulation in R.)